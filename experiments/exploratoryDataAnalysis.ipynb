{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only reading in one email for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailDir = \"./maildir/maildir\"\n",
    "enroncsv = \"../experiments/enron.csv\"\n",
    "metadataHeaders = '../experiments/metadataHeaders.csv'\n",
    "spam = '../experiments/spam.csv'\n",
    "spamSubjects = '../experiments/spamWords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Filename',\n",
       " 'Person',\n",
       " 'Directory',\n",
       " 'Message-ID',\n",
       " 'Date',\n",
       " 'From',\n",
       " 'To',\n",
       " 'Subject',\n",
       " 'Cc',\n",
       " 'Time',\n",
       " 'Attendees',\n",
       " 'Re',\n",
       " 'Mime-Version',\n",
       " 'Content-Type',\n",
       " 'Content-Transfer-Encoding',\n",
       " 'Bcc',\n",
       " 'X-From',\n",
       " 'X-To',\n",
       " 'X-cc',\n",
       " 'X-bcc',\n",
       " 'X-Folder',\n",
       " 'X-Origin',\n",
       " 'X-FileName']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = pd.read_csv(metadataHeaders, sep=',').columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(enroncsv, names=columns, sep='|', low_memory=False)\n",
    "\n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets query for a mail that does not have `Message-ID` with `.JavaMail.evans@thyme`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Person</th>\n",
       "      <th>Directory</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Cc</th>\n",
       "      <th>Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>Bcc</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Filename, Person, Directory, Message-ID, Date, From, To, Subject, Cc, Time, Attendees, Re, Mime-Version, Content-Type, Content-Transfer-Encoding, Bcc, X-From, X-To, X-cc, X-bcc, X-Folder, X-Origin, X-FileName]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df[pd.notnull(df['Message-ID'])]\n",
    "\n",
    "result = result.loc[~result['Message-ID'].str.contains('.JavaMail.evans@thyme')]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df[pd.notnull(df['Subject'])]\n",
    "\n",
    "result = result.loc[result['Subject'].str.contains('Porn')]\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No results so the server `.JavaMail.evans@thyme` is not helpfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets count the number of non null fields per header and make it a percentage over the total number of parsable emials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filename                      0.000000\n",
       "Person                        0.000000\n",
       "Directory                     0.000000\n",
       "Message-ID                    0.000387\n",
       "Date                          0.000387\n",
       "From                          0.000387\n",
       "To                            4.222880\n",
       "Subject                       3.713189\n",
       "Cc                           75.279489\n",
       "Time                         99.999807\n",
       "Attendees                    99.994201\n",
       "Re                           99.998840\n",
       "Mime-Version                  0.011597\n",
       "Content-Type                  0.011597\n",
       "Content-Transfer-Encoding     0.010631\n",
       "Bcc                          75.284322\n",
       "X-From                        0.011404\n",
       "X-To                          1.770680\n",
       "X-cc                         75.084079\n",
       "X-bcc                        99.959410\n",
       "X-Folder                      0.012370\n",
       "X-Origin                      0.006958\n",
       "X-FileName                    0.820493\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numberOfRows = len(df.index)\n",
    "missingData = (numberOfRows - df.count()) / numberOfRows * 100\n",
    "plot = missingData.plot(kind='bar')\n",
    "\n",
    "plt.show()\n",
    "missingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people flolders don't match their X-origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['Person'] != df['X-Origin'].str.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different `Content-Type`'s are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'text/plain; charset=\"us-ascii\"',\n",
       "       'text/plain; charset=\"ANSI_X3.4-1968\"'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content-Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different `Content-Transfer-Encoding`'s are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '7bit', 'quoted-printable', 'base64',\n",
       "       '\\\\JSKILLIN (Non-Privileged)\\\\Deleted Items', '\\\\jskillin\\\\Inbox',\n",
       "       '\\\\HARORA (Non-Privileged)\\\\Arora, Harry\\\\Deleted Items',\n",
       "       '\\\\HARORA (Non-Privileged)\\\\Arora, Harry\\\\Inbox',\n",
       "       'EID: <24606> ERe: <0>'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content-Transfer-Encoding'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different `Mime-Version`'s are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mime-Version'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove those colums that are almost never filled in or that are irrelevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "removableColumns = ['Time', 'Attendees', 'Bcc', 'X-bcc', 'X-cc', 'X-Origin']\n",
    "\n",
    "import csv\n",
    "with open('removableColumns.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for col in removableColumns:\n",
    "        writer.writerow([col])\n",
    "\n",
    "df.drop(removableColumns, axis=1)\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "listOfEmailsForBagOfWords = df.loc[df['Directory'].str.contains('inbox')]\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498161"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = df[pd.notnull(df['Subject'])]\n",
    "nonSpamSubjects = wordsPerEmail['Subject']\n",
    "wordsPerEmail = nonSpamSubjects.str.split(' ')\n",
    "len(wordsPerEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "printable = set(string.printable)\n",
    "\n",
    "def isEnglish(s):\n",
    "    for x in s:\n",
    "        if x not in printable:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def addToBagOfWords(dictionary, arr):\n",
    "    for word in arr:\n",
    "        word = word.lower()\n",
    "        \n",
    "        if '=' in word:\n",
    "            continue\n",
    "        if '/' in word:\n",
    "            continue\n",
    "        if '\\\\' in word:\n",
    "            continue\n",
    "        if '_' in word:\n",
    "            continue\n",
    "        if '-' in word:\n",
    "            continue\n",
    "        if ':' in word:\n",
    "            continue\n",
    "        if '@' in word:\n",
    "            continue\n",
    "        if '#' in word:\n",
    "            continue\n",
    "        if '$' in word:\n",
    "            word = '$'\n",
    "\n",
    "        word = word.replace('.', '')\n",
    "        word = word.replace(')', '')\n",
    "        word = word.replace('(', '')\n",
    "        word = word.replace('&', '')\n",
    "        word = word.replace('\\'', '')\n",
    "        word = word.replace('\\\"', '')\n",
    "        word = word.replace(',', '')\n",
    "        word = word.replace('[', '')\n",
    "        word = word.replace(']', '')\n",
    "        word = word.replace('{', '')\n",
    "        word = word.replace('}', '')\n",
    "        word = word.replace(';', '')\n",
    "\n",
    "        if word == '':\n",
    "            continue\n",
    "\n",
    "        if word in dictionary:\n",
    "            dictionary[word] = dictionary[word] + 1\n",
    "        else:\n",
    "            dictionary[word] = 1\n",
    "            \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToDictionary(dictionary, arr):\n",
    "    for index, subject in arr.iteritems():\n",
    "        dictionary = addToBagOfWords(dictionary, subject)\n",
    "                \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39519"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spamSubjects = pd.read_csv(spam, names=['Subject'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45090"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = spamSubjects['Subject'].str.split(' ')\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45090"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = []\n",
    "for key in dictionary:\n",
    "    dictionaryList.append([key, dictionary[key]])\n",
    "    \n",
    "dictionaryList = pd.DataFrame(dictionaryList, columns=[\"Word\", \"Occurances\"])\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use words that occurred more than 30 times in our bag of words as other words would almost never match up anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5751"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = dictionaryList.loc[dictionaryList['Occurances'] > 30].reset_index(drop=True)\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBagToInputOutput(inputItems, outputItems, arr):\n",
    "    for index, subject in inputItems.iteritems():\n",
    "        posBagOfWords = {}\n",
    "        posBagOfWords = addToBagOfWords(posBagOfWords, subject)\n",
    "\n",
    "        listOfIn = []\n",
    "        for key in posBagOfWords:\n",
    "            listOfIn.append(key)\n",
    "\n",
    "        inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "\n",
    "        arr.append([np.array(inputBag), np.array(outputItems)])\n",
    "        \n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "\n",
    "NON_SPAM_SAMPLES = 1000\n",
    "SPAM_SAMPLES = 1000\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "training = addBagToInputOutput(trainingPosSplit, [0], training)\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "    \n",
    "training = addBagToInputOutput(trainingNegSplit, [1], training)\n",
    "\n",
    "training = np.array(training)\n",
    "np.random.shuffle(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up a neuarl network with neurons on each layer \n",
    "\n",
    "    input - 5558 + bias\n",
    "    hidden layer 1 - 200 + bias\n",
    "    hidden layer 2 - 20 + bias\n",
    "    output - 1\n",
    "    \n",
    "The learing rate is set to 0.001\n",
    "The netword is bound to (-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.dataSet.dataSetTool import DataSetTool\n",
    "from mlpy.numberGenerator.bounds import Bounds\n",
    "from mlpy.neuralNetwork.feedForwardNeuralNetwork import NeuralNetwork\n",
    "from mlpy.neuralNetwork.structure.layer import Layer\n",
    "\n",
    "l_rate = 0.001\n",
    "bounds = Bounds(-2, 2)\n",
    "\n",
    "inputLayer = Layer(bounds, size = len(training[0][0]), prev = None, l_rate = l_rate, bias = True, label = \"Input layer\")\n",
    "hiddenLayer = Layer(bounds, size = 200, prev = inputLayer, l_rate = l_rate, bias = True, label = \"Hidden layer\")\n",
    "hiddenLayer2 = Layer(bounds, size = 20, prev = hiddenLayer, l_rate = l_rate, bias = True, label = \"Hidden layer 2\")\n",
    "outputLayer = Layer(bounds, size = len(training[0][1]), prev = hiddenLayer2, l_rate = l_rate, bias = False, label = \"Output layer\")\n",
    "\n",
    "fnn = NeuralNetwork()\n",
    "fnn.appendLayer(inputLayer)\n",
    "fnn.appendLayer(hiddenLayer)\n",
    "fnn.appendLayer(hiddenLayer2)\n",
    "fnn.appendLayer(outputLayer)\n",
    "\n",
    "group_training = np.array([input[0] for input in training])\n",
    "group_target = np.array([output[1] for output in training])\n",
    "\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run training over 4000 iterations and output the mean error every 200 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting..\n",
      "0.0%\t -0.4933851726913382\n",
      "5.0%\t 0.006012085026811531\n",
      "10.0%\t 0.006672171233949033\n",
      "15.0%\t 0.00549388749043379\n",
      "20.0%\t 0.0042715638584491485\n",
      "25.0%\t 0.0029375531431918302\n",
      "30.0%\t 0.0010883441990222832\n",
      "35.0%\t -0.0009302758861765845\n",
      "40.0%\t -0.002857269648429512\n",
      "45.0%\t -0.004040743812483065\n",
      "50.0%\t -0.004770119083515166\n",
      "55.0%\t -0.005135375949801913\n",
      "60.0%\t -0.004981631866698426\n",
      "65.0%\t -0.004426896547979901\n",
      "70.0%\t -0.00395877723315678\n",
      "75.0%\t -0.003364601650913845\n",
      "80.0%\t -0.003226923725698198\n",
      "85.0%\t -0.0034013987274191127\n",
      "90.0%\t -0.0037048881855799194\n",
      "95.0%\t -0.004012315757492615\n",
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 4000\n",
    "\n",
    "print(\"Starting..\")\n",
    "for i in range(ITERATIONS):\n",
    "    mod = i % len(training)\n",
    "    in_out = training[mod]\n",
    "    result = fnn.fire(group_training)\n",
    "    error = fnn.backPropagation(group_target)\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(str(np.round(i/ITERATIONS*100)) + '%\\t', error.mean())\n",
    "    \n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = []\n",
    "\n",
    "TEST_NON_SPAM_SAMPLES = 250\n",
    "TEST_SPAM_SAMPLES = 250\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(TEST_NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "testing = addBagToInputOutput(trainingPosSplit, [0], testing)\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(TEST_SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "\n",
    "testing = addBagToInputOutput(trainingNegSplit, [1], testing)\n",
    "\n",
    "testing = np.array(testing)\n",
    "np.random.shuffle(testing)\n",
    "\n",
    "len(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model we will take the test data and use it as an measure of performace. The following will be output:\n",
    "\n",
    "1. The Classification Accuracy\n",
    "2. The Non-spam Classsification accuracy\n",
    "3. The Spam Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.748\n",
      "Non spam classification accuracy:  0.74\n",
      "Spam classification accuracy:  0.756\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "spamCorrect = 0\n",
    "nonSpamCorrect = 0\n",
    "for i in range(len(testing)):\n",
    "    in_out = testing[i]\n",
    "    result = fnn.fire(np.array([in_out[0]]))\n",
    "    \n",
    "    target = in_out[1][0]\n",
    "    result = np.round(result[0][0])\n",
    "\n",
    "    if result == target:\n",
    "        correct += 1\n",
    "        if target == 1:\n",
    "            spamCorrect += 1\n",
    "        else:\n",
    "            nonSpamCorrect += 1\n",
    "        \n",
    "        \n",
    "print(\"Classification accuracy: \", correct / len(testing))\n",
    "print(\"Non spam classification accuracy: \", nonSpamCorrect / TEST_NON_SPAM_SAMPLES)\n",
    "print(\"Spam classification accuracy: \", spamCorrect / TEST_SPAM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
