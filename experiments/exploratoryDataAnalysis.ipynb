{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only reading in one email for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailDir = \"./maildir/maildir\"\n",
    "enroncsv = \"../experiments/enron.csv\"\n",
    "metadataHeaders = '../experiments/metadataHeaders.csv'\n",
    "spam = '../experiments/spam.csv'\n",
    "spamSubjects = '../experiments/spamWords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Filename',\n",
       " 'Person',\n",
       " 'Directory',\n",
       " 'Message-ID',\n",
       " 'Date',\n",
       " 'From',\n",
       " 'To',\n",
       " 'Subject',\n",
       " 'Cc',\n",
       " 'Time',\n",
       " 'Attendees',\n",
       " 'Re',\n",
       " 'Mime-Version',\n",
       " 'Content-Type',\n",
       " 'Content-Transfer-Encoding',\n",
       " 'Bcc',\n",
       " 'X-From',\n",
       " 'X-To',\n",
       " 'X-cc',\n",
       " 'X-bcc',\n",
       " 'X-Folder',\n",
       " 'X-Origin',\n",
       " 'X-FileName']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = pd.read_csv(metadataHeaders, sep=',').columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(enroncsv, names=columns, sep='|', low_memory=False)\n",
    "\n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets query for a mail that does not have `Message-ID` with `.JavaMail.evans@thyme`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Person</th>\n",
       "      <th>Directory</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Cc</th>\n",
       "      <th>Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>Bcc</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Filename, Person, Directory, Message-ID, Date, From, To, Subject, Cc, Time, Attendees, Re, Mime-Version, Content-Type, Content-Transfer-Encoding, Bcc, X-From, X-To, X-cc, X-bcc, X-Folder, X-Origin, X-FileName]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df[pd.notnull(df['Message-ID'])]\n",
    "\n",
    "result = result.loc[~result['Message-ID'].str.contains('.JavaMail.evans@thyme')]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df[pd.notnull(df['Subject'])]\n",
    "\n",
    "result = result.loc[result['Subject'].str.contains('Porn')]\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No results so the server `.JavaMail.evans@thyme` is not helpfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets count the number of non null fields per header and make it a percentage over the total number of parsable emials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filename                      0.000000\n",
       "Person                        0.000000\n",
       "Directory                     0.000000\n",
       "Message-ID                    0.000387\n",
       "Date                          0.000387\n",
       "From                          0.000387\n",
       "To                            4.222880\n",
       "Subject                       3.713189\n",
       "Cc                           75.279489\n",
       "Time                         99.999807\n",
       "Attendees                    99.994201\n",
       "Re                           99.998840\n",
       "Mime-Version                  0.011597\n",
       "Content-Type                  0.011597\n",
       "Content-Transfer-Encoding     0.010631\n",
       "Bcc                          75.284322\n",
       "X-From                        0.011404\n",
       "X-To                          1.770680\n",
       "X-cc                         75.084079\n",
       "X-bcc                        99.959410\n",
       "X-Folder                      0.012370\n",
       "X-Origin                      0.006958\n",
       "X-FileName                    0.820493\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numberOfRows = len(df.index)\n",
    "missingData = (numberOfRows - df.count()) / numberOfRows * 100\n",
    "plot = missingData.plot(kind='bar')\n",
    "\n",
    "plt.show()\n",
    "missingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people flolders don't match their X-origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['Person'] != df['X-Origin'].str.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different `Content-Type`'s are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'text/plain; charset=\"us-ascii\"',\n",
       "       'text/plain; charset=\"ANSI_X3.4-1968\"'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content-Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different `Content-Transfer-Encoding`'s are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '7bit', 'quoted-printable', 'base64',\n",
       "       '\\\\JSKILLIN (Non-Privileged)\\\\Deleted Items', '\\\\jskillin\\\\Inbox',\n",
       "       '\\\\HARORA (Non-Privileged)\\\\Arora, Harry\\\\Deleted Items',\n",
       "       '\\\\HARORA (Non-Privileged)\\\\Arora, Harry\\\\Inbox',\n",
       "       'EID: <24606> ERe: <0>'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content-Transfer-Encoding'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different `Mime-Version`'s are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mime-Version'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove those colums that are almost never filled in or that are irrelevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "removableColumns = ['Time', 'Attendees', 'Bcc', 'X-bcc', 'X-cc', 'X-Origin']\n",
    "\n",
    "import csv\n",
    "with open('removableColumns.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for col in removableColumns:\n",
    "        writer.writerow([col])\n",
    "\n",
    "df.drop(removableColumns, axis=1)\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "listOfEmailsForBagOfWords = df.loc[df['Directory'].str.contains('inbox')]\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498161"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = df[pd.notnull(df['Subject'])]\n",
    "nonSpamSubjects = wordsPerEmail['Subject']\n",
    "wordsPerEmail = nonSpamSubjects.str.split(' ')\n",
    "len(wordsPerEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "printable = set(string.printable)\n",
    "\n",
    "def isEnglish(s):\n",
    "    for x in s:\n",
    "        if x not in printable:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def addToBagOfWords(dictionary, arr):\n",
    "    for word in arr:\n",
    "        word = word.lower()\n",
    "        \n",
    "        if '=' in word:\n",
    "            continue\n",
    "        if '/' in word:\n",
    "            continue\n",
    "        if '\\\\' in word:\n",
    "            continue\n",
    "        if '_' in word:\n",
    "            continue\n",
    "        if '-' in word:\n",
    "            continue\n",
    "        if ':' in word:\n",
    "            continue\n",
    "        if '@' in word:\n",
    "            continue\n",
    "        if '#' in word:\n",
    "            continue\n",
    "        if '$' in word:\n",
    "            word = '$'\n",
    "\n",
    "        word = word.replace('.', '')\n",
    "        word = word.replace(')', '')\n",
    "        word = word.replace('(', '')\n",
    "        word = word.replace('&', '')\n",
    "        word = word.replace('\\'', '')\n",
    "        word = word.replace('\\\"', '')\n",
    "        word = word.replace(',', '')\n",
    "        word = word.replace('[', '')\n",
    "        word = word.replace(']', '')\n",
    "        word = word.replace('{', '')\n",
    "        word = word.replace('}', '')\n",
    "        word = word.replace(';', '')\n",
    "\n",
    "        if word == '':\n",
    "            continue\n",
    "\n",
    "        if word in dictionary:\n",
    "            dictionary[word] = dictionary[word] + 1\n",
    "        else:\n",
    "            dictionary[word] = 1\n",
    "            \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToDictionary(dictionary, arr):\n",
    "    for index, subject in arr.iteritems():\n",
    "        dictionary = addToBagOfWords(dictionary, subject)\n",
    "                \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39519"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spamSubjects = pd.read_csv(spamSubjects, names=['Subject'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39549"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = spamSubjects['Subject'].str.split(' ')\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39549"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = []\n",
    "for key in dictionary:\n",
    "    dictionaryList.append([key, dictionary[key]])\n",
    "    \n",
    "dictionaryList = pd.DataFrame(dictionaryList, columns=[\"Word\", \"Occurances\"])\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5558"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = dictionaryList.loc[dictionaryList['Occurances'] > 30].reset_index(drop=True)\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "\n",
    "NON_SPAM_SAMPLES = 1000\n",
    "SPAM_SAMPLES = len(spamSubjects)\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "for index, subject in trainingPosSplit.iteritems():\n",
    "    posBagOfWords = {}\n",
    "    posBagOfWords = addToBagOfWords(posBagOfWords, subject)\n",
    "    \n",
    "    listOfIn = []\n",
    "    for key in posBagOfWords:\n",
    "        listOfIn.append(key)\n",
    "    \n",
    "    inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "    \n",
    "    training.append([np.array(inputBag), np.array([0])])\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "\n",
    "for index, subject in trainingNegSplit.iteritems():\n",
    "    negBagOfWords = {}\n",
    "    negBagOfWords = addToBagOfWords(negBagOfWords, subject)\n",
    "    \n",
    "    listOfIn = []\n",
    "    for key in negBagOfWords:\n",
    "        listOfIn.append(key)\n",
    "    \n",
    "    inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "    \n",
    "    training.append([np.array(inputBag), np.array([1])])\n",
    "\n",
    "training = np.array(training)\n",
    "np.random.shuffle(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.dataSet.dataSetTool import DataSetTool\n",
    "from mlpy.numberGenerator.bounds import Bounds\n",
    "from mlpy.neuralNetwork.feedForwardNeuralNetwork import NeuralNetwork\n",
    "from mlpy.neuralNetwork.structure.layer import Layer\n",
    "\n",
    "l_rate = 0.001\n",
    "bounds = Bounds(-2, 2)\n",
    "\n",
    "inputLayer = Layer(bounds, size = len(training[0][0]), prev = None, l_rate = l_rate, bias = True, label = \"Input layer\")\n",
    "hiddenLayer = Layer(bounds, size = 200, prev = inputLayer, l_rate = l_rate, bias = True, label = \"Hidden layer\")\n",
    "hiddenLayer2 = Layer(bounds, size = 20, prev = hiddenLayer, l_rate = l_rate, bias = True, label = \"Hidden layer 2\")\n",
    "outputLayer = Layer(bounds, size = len(training[0][1]), prev = hiddenLayer2, l_rate = l_rate, bias = False, label = \"Output layer\")\n",
    "\n",
    "fnn = NeuralNetwork()\n",
    "fnn.appendLayer(inputLayer)\n",
    "fnn.appendLayer(hiddenLayer)\n",
    "fnn.appendLayer(hiddenLayer2)\n",
    "fnn.appendLayer(outputLayer)\n",
    "\n",
    "group_training = np.array([input[0] for input in training])\n",
    "group_target = np.array([output[1] for output in training])\n",
    "\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting..\n",
      "-0.36775262841674716\n",
      "0.04877275053931843\n",
      "0.02133254372429527\n",
      "0.008372047465422526\n",
      "0.002916901445840433\n",
      "0.00035713937182961275\n",
      "-0.0012791167002708917\n",
      "-0.0024987526170419188\n",
      "-0.0034607732719814147\n",
      "-0.004230932293276721\n",
      "-0.004856486333782484\n",
      "-0.005393664186084141\n",
      "-0.005879687916016475\n",
      "-0.00631501683153125\n",
      "-0.006688113915487953\n",
      "-0.006990866677513786\n",
      "-0.0072192457773339845\n",
      "-0.007366065528199428\n",
      "-0.0074066842124670285\n",
      "-0.007305342144923007\n",
      "-0.007059747409307591\n",
      "-0.006693084378155808\n",
      "-0.0062453237638714605\n",
      "-0.005776479131806317\n",
      "-0.005340142985604143\n",
      "-0.004967821507346416\n",
      "-0.004680312458473453\n",
      "-0.004501514529929714\n",
      "-0.004452367417277723\n",
      "-0.004500285291124079\n",
      "-0.00456463273920163\n",
      "-0.004497407311918768\n",
      "-0.004041116702268134\n",
      "-0.003395699095019259\n",
      "-0.0028247333007924568\n",
      "-0.0023574413873951507\n",
      "-0.001939945941744941\n",
      "-0.0015781632517008705\n",
      "-0.0012959629984396212\n",
      "-0.0010807934288644308\n",
      "-0.0008881385626342962\n",
      "-0.0006765000556792661\n",
      "-0.0004379277544421446\n",
      "-0.0001749885803291419\n",
      "0.0001484617672597675\n",
      "0.0006013496428605987\n",
      "0.001154909819824971\n",
      "0.0016470280520514634\n",
      "0.001994215045837762\n",
      "0.002249009980421813\n",
      "0.002424548375516798\n",
      "0.002535259645087594\n",
      "0.0025980035899829264\n",
      "0.002625605779811873\n",
      "0.002643730306875497\n",
      "0.002700517706847393\n",
      "0.002823729130105995\n",
      "0.0029750018658465105\n",
      "0.0030970684952805155\n",
      "0.003155144830775576\n",
      "0.0031289798963794837\n",
      "0.003040248067161471\n",
      "0.0029868516686120026\n",
      "0.0029366507154993233\n",
      "0.002831208508741881\n",
      "0.002670468858927176\n",
      "0.0024750132926844156\n",
      "0.002260492277442165\n",
      "0.0020357591741965416\n",
      "0.0018148102677688642\n",
      "0.0015680614563668403\n",
      "0.0012196357544622027\n",
      "0.0009105305863505094\n",
      "0.0008726977842947747\n",
      "0.0009028660573580983\n",
      "0.0008717481575656554\n",
      "0.0007023649023039964\n",
      "0.00028280001534153456\n",
      "-8.613000406142407e-05\n",
      "-0.00013874265581723317\n",
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting..\")\n",
    "for i in range(4000):\n",
    "    mod = i % len(training)\n",
    "    in_out = training[mod]\n",
    "    result = fnn.fire(group_training)\n",
    "    i_error = fnn.backPropagation(group_target)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i_error.mean())\n",
    "    \n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = []\n",
    "\n",
    "TEST_NON_SPAM_SAMPLES = 250\n",
    "TEST_SPAM_SAMPLES = len(spamSubjects)\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(TEST_NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "for index, subject in trainingPosSplit.iteritems():\n",
    "    posBagOfWords = {}\n",
    "    posBagOfWords = addToBagOfWords(posBagOfWords, subject)\n",
    "    \n",
    "    listOfIn = []\n",
    "    for key in posBagOfWords:\n",
    "        listOfIn.append(key)\n",
    "    \n",
    "    inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "    \n",
    "    testing.append([np.array(inputBag), np.array([0])])\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(TEST_SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "\n",
    "for index, subject in trainingNegSplit.iteritems():\n",
    "    negBagOfWords = {}\n",
    "    negBagOfWords = addToBagOfWords(negBagOfWords, subject)\n",
    "    \n",
    "    listOfIn = []\n",
    "    for key in negBagOfWords:\n",
    "        listOfIn.append(key)\n",
    "    \n",
    "    inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "    \n",
    "    testing.append([np.array(inputBag), np.array([1])])\n",
    "\n",
    "testing = np.array(testing)\n",
    "np.random.shuffle(testing)\n",
    "\n",
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.8977955911823647\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f13b204ff953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classification accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Non spam classification accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonSpamCorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spam classification accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspamCorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspamSubjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "spamCorrect = 0\n",
    "nonSpamCorrect = 0\n",
    "for i in range(len(testing)):\n",
    "    in_out = testing[i]\n",
    "    result = fnn.fire(np.array([in_out[0]]))\n",
    "    \n",
    "    target = in_out[1][0]\n",
    "    result = np.round(result[0][0])\n",
    "\n",
    "    if result == target:\n",
    "        correct += 1\n",
    "        if target == 1:\n",
    "            spamCorrect += 1\n",
    "        else:\n",
    "            nonSpamCorrect += 1\n",
    "        \n",
    "        \n",
    "print(\"classification accuracy: \", correct / len(testing))\n",
    "print(\"Non spam classification accuracy: \", nonSpamCorrect / TEST_NON_SPAM_SAMPLES)\n",
    "print(\"Spam classification accuracy: \", spamCorrect / TEST_SPAM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
