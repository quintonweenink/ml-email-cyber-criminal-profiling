{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only reading in one email for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroncsv = \"../experiments/data/anon.csv\"\n",
    "metadataHeaders = '../experiments/data/metadataHeaders.csv'\n",
    "spam = '../experiments/data/spam.csv'\n",
    "spamSubjects = '../experiments/data/spamWords.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = pd.read_csv(metadataHeaders, sep=',').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(enroncsv, names=columns, sep='|', low_memory=False)\n",
    "\n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "removableColumns = pd.read_csv('data/removableColumns.csv', sep=',').columns.tolist()\n",
    "\n",
    "df.drop(removableColumns, axis=1)\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "listOfEmailsForBagOfWords = df.loc[df['Directory'].str.contains('inbox')]\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = df[pd.notnull(df['Subject'])]\n",
    "nonSpamSubjects = wordsPerEmail['Subject']\n",
    "wordsPerEmail = nonSpamSubjects.str.split(' ')\n",
    "len(wordsPerEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "printable = set(string.printable)\n",
    "\n",
    "def isEnglish(s):\n",
    "    for x in s:\n",
    "        if x not in printable:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def addToBagOfWords(dictionary, arr):\n",
    "    for word in arr:\n",
    "        word = word.lower()\n",
    "        \n",
    "        if '=' in word:\n",
    "            continue\n",
    "        if '/' in word:\n",
    "            continue\n",
    "        if '\\\\' in word:\n",
    "            continue\n",
    "        if '_' in word:\n",
    "            continue\n",
    "        if '-' in word:\n",
    "            continue\n",
    "        if ':' in word:\n",
    "            continue\n",
    "        if '@' in word:\n",
    "            continue\n",
    "        if '#' in word:\n",
    "            continue\n",
    "        if '$' in word:\n",
    "            word = '$'\n",
    "\n",
    "        word = word.replace('.', '')\n",
    "        word = word.replace(')', '')\n",
    "        word = word.replace('(', '')\n",
    "        word = word.replace('&', '')\n",
    "        word = word.replace('\\'', '')\n",
    "        word = word.replace('\\\"', '')\n",
    "        word = word.replace(',', '')\n",
    "        word = word.replace('[', '')\n",
    "        word = word.replace(']', '')\n",
    "        word = word.replace('{', '')\n",
    "        word = word.replace('}', '')\n",
    "        word = word.replace(';', '')\n",
    "\n",
    "        if word == '':\n",
    "            continue\n",
    "\n",
    "        if word in dictionary:\n",
    "            dictionary[word] = dictionary[word] + 1\n",
    "        else:\n",
    "            dictionary[word] = 1\n",
    "            \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToDictionary(dictionary, arr):\n",
    "    for index, subject in arr.iteritems():\n",
    "        dictionary = addToBagOfWords(dictionary, subject)\n",
    "                \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39519"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spamSubjects = pd.read_csv(spam, names=['Subject'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45090"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = spamSubjects['Subject'].str.split(' ')\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45090"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = []\n",
    "for key in dictionary:\n",
    "    dictionaryList.append([key, dictionary[key]])\n",
    "    \n",
    "dictionaryList = pd.DataFrame(dictionaryList, columns=[\"Word\", \"Occurances\"])\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use words that occurred more than 30 times in our bag of words as other words would almost never match up anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5751"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = dictionaryList.loc[dictionaryList['Occurances'] > 30].reset_index(drop=True)\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBagToInputOutput(inputItems, outputItems, arr):\n",
    "    for index, subject in inputItems.iteritems():\n",
    "        posBagOfWords = {}\n",
    "        posBagOfWords = addToBagOfWords(posBagOfWords, subject)\n",
    "\n",
    "        listOfIn = []\n",
    "        for key in posBagOfWords:\n",
    "            listOfIn.append(key)\n",
    "\n",
    "        inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "\n",
    "        arr.append([np.array(inputBag), np.array(outputItems)])\n",
    "        \n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "\n",
    "NON_SPAM_SAMPLES = 1000\n",
    "SPAM_SAMPLES = 1000\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "training = addBagToInputOutput(trainingPosSplit, [0], training)\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "    \n",
    "training = addBagToInputOutput(trainingNegSplit, [1], training)\n",
    "\n",
    "training = np.array(training)\n",
    "np.random.shuffle(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up a neuarl network with neurons on each layer \n",
    "\n",
    "    input - 5558 + bias\n",
    "    hidden layer 1 - 200 + bias\n",
    "    hidden layer 2 - 20 + bias\n",
    "    output - 1\n",
    "    \n",
    "The learing rate is set to 0.001\n",
    "The netword is bound to (-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.numberGenerator.bounds import Bounds\n",
    "from mlpy.neuralNetwork.feedForwardNeuralNetwork import NeuralNetwork\n",
    "from mlpy.neuralNetwork.structure.layer import Layer\n",
    "\n",
    "l_rate = 0.001\n",
    "bounds = Bounds(-2, 2)\n",
    "\n",
    "inputLayer = Layer(bounds, size = len(training[0][0]), prev = None, l_rate = l_rate, bias = True, label = \"Input layer\")\n",
    "hiddenLayer = Layer(bounds, size = 200, prev = inputLayer, l_rate = l_rate, bias = True, label = \"Hidden layer\")\n",
    "hiddenLayer2 = Layer(bounds, size = 20, prev = hiddenLayer, l_rate = l_rate, bias = True, label = \"Hidden layer 2\")\n",
    "outputLayer = Layer(bounds, size = len(training[0][1]), prev = hiddenLayer2, l_rate = l_rate, bias = False, label = \"Output layer\")\n",
    "\n",
    "fnn = NeuralNetwork()\n",
    "fnn.appendLayer(inputLayer)\n",
    "fnn.appendLayer(hiddenLayer)\n",
    "fnn.appendLayer(hiddenLayer2)\n",
    "fnn.appendLayer(outputLayer)\n",
    "\n",
    "group_training = np.array([input[0] for input in training])\n",
    "group_target = np.array([output[1] for output in training])\n",
    "\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run training over 4000 iterations and output the mean error every 200 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting..\n",
      "0.0%\t -0.2765026234057767\n",
      "5.0%\t -0.003050694372103209\n",
      "10.0%\t 0.00010212984489931553\n",
      "15.0%\t -7.728464215698416e-05\n",
      "20.0%\t -0.0008527255661347808\n",
      "25.0%\t -0.0016278042466524954\n",
      "30.0%\t -0.0021047060910248804\n",
      "35.0%\t -0.0023617466117687434\n",
      "40.0%\t -0.0022234871782112735\n",
      "45.0%\t -0.0020463127504577773\n",
      "50.0%\t -0.0015229964999428193\n",
      "55.0%\t -0.0010783260052427495\n",
      "60.0%\t -0.0007169712542621996\n",
      "65.0%\t -0.0003052411620596356\n",
      "70.0%\t -0.0002725217854694817\n",
      "75.0%\t -0.0003113240461118918\n",
      "80.0%\t -0.0003045537326310288\n",
      "85.0%\t 9.88297671506404e-05\n",
      "90.0%\t -0.00010332489543996725\n",
      "95.0%\t 0.00012965235437434442\n",
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 4000\n",
    "\n",
    "print(\"Starting..\")\n",
    "for i in range(ITERATIONS):\n",
    "    mod = i % len(training)\n",
    "    in_out = training[mod]\n",
    "    result = fnn.fire(group_training)\n",
    "    error = fnn.backPropagation(group_target)\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(str(np.round(i/ITERATIONS*100)) + '%\\t', error.mean())\n",
    "    \n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = []\n",
    "\n",
    "TEST_NON_SPAM_SAMPLES = 250\n",
    "TEST_SPAM_SAMPLES = 250\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(TEST_NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "testing = addBagToInputOutput(trainingPosSplit, [0], testing)\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(TEST_SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "\n",
    "testing = addBagToInputOutput(trainingNegSplit, [1], testing)\n",
    "\n",
    "testing = np.array(testing)\n",
    "np.random.shuffle(testing)\n",
    "\n",
    "len(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model we will take the test data and use it as an measure of performace. The following will be output:\n",
    "\n",
    "1. The Classification Accuracy\n",
    "2. The Non-spam Classsification accuracy\n",
    "3. The Spam Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.754\n",
      "Non spam classification accuracy:  0.744\n",
      "Spam classification accuracy:  0.764\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "spamCorrect = 0\n",
    "nonSpamCorrect = 0\n",
    "for i in range(len(testing)):\n",
    "    in_out = testing[i]\n",
    "    result = fnn.fire(np.array([in_out[0]]))\n",
    "    \n",
    "    target = in_out[1][0]\n",
    "    result = np.round(result[0][0])\n",
    "\n",
    "    if result == target:\n",
    "        correct += 1\n",
    "        if target == 1:\n",
    "            spamCorrect += 1\n",
    "        else:\n",
    "            nonSpamCorrect += 1\n",
    "        \n",
    "        \n",
    "print(\"Classification accuracy: \", correct / len(testing))\n",
    "print(\"Non spam classification accuracy: \", nonSpamCorrect / TEST_NON_SPAM_SAMPLES)\n",
    "print(\"Spam classification accuracy: \", spamCorrect / TEST_SPAM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets apply the classifier to a subset of the data to see what it classifies as spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115264</th>\n",
       "      <td>Deal 156071 Feb 00</td>\n",
       "      <td>0.916513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131332</th>\n",
       "      <td>Sivy on Stocks: Winning a loser's game</td>\n",
       "      <td>0.995735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98391</th>\n",
       "      <td>RE: can't you defer the ecogas depos? richard ...</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74051</th>\n",
       "      <td>4/4/01 Churn</td>\n",
       "      <td>0.927261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360290</th>\n",
       "      <td>FW: Exchange Cash</td>\n",
       "      <td>0.915055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300667</th>\n",
       "      <td>RE: CLE Program - Antitrust Issues Relating to...</td>\n",
       "      <td>0.976513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300448</th>\n",
       "      <td>RE: phone numbers</td>\n",
       "      <td>0.971287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493360</th>\n",
       "      <td>Australia &amp; Japan</td>\n",
       "      <td>0.974225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100269</th>\n",
       "      <td>old bills</td>\n",
       "      <td>0.998415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Subject  Classification\n",
       "115264                                 Deal 156071 Feb 00        0.916513\n",
       "131332             Sivy on Stocks: Winning a loser's game        0.995735\n",
       "98391   RE: can't you defer the ecogas depos? richard ...        0.999483\n",
       "74051                                        4/4/01 Churn        0.927261\n",
       "360290                                  FW: Exchange Cash        0.915055\n",
       "300667  RE: CLE Program - Antitrust Issues Relating to...        0.976513\n",
       "300448                                  RE: phone numbers        0.971287\n",
       "493360                                  Australia & Japan        0.974225\n",
       "100269                                          old bills        0.998415"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClassify = df.drop(['Filename', 'Person', 'Directory', 'Message-ID', 'Content-Transfer-Encoding', 'Content-Type', 'Date', 'X-FileName', 'From', 'X-To', 'X-bcc', 'Cc', 'X-cc', 'To', 'X-Folder', 'X-Origin', 'Time', 'Bcc', 'X-From', 'Attendees', 'Re', 'Mime-Version'], axis=1)\n",
    "\n",
    "dfClassify = dfClassify[pd.notnull(df['Subject'])]\n",
    "dfClassify = dfClassify.sample(100)\n",
    "\n",
    "def classify(arr):\n",
    "    classifySplit = arr.split(' ')\n",
    "    \n",
    "    posBagOfWords = {}\n",
    "    posBagOfWords = addToBagOfWords(posBagOfWords, classifySplit)\n",
    "\n",
    "    listOfIn = []\n",
    "    for key in posBagOfWords:\n",
    "        listOfIn.append(key)\n",
    "\n",
    "    inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "    \n",
    "    result = fnn.fire(np.array([np.array(inputBag)]))[0][0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "dfClassify['Classification'] = dfClassify['Subject'].apply(classify)\n",
    "    \n",
    "dfClassify[dfClassify['Classification'] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
