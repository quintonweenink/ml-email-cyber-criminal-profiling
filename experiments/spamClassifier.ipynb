{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only reading in one email for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroncsv = \"../experiments/data/anon.csv\"\n",
    "metadataHeaders = '../experiments/data/metadataHeaders.csv'\n",
    "spam = '../experiments/data/spam.csv'\n",
    "spamSubjects = '../experiments/data/spamWords.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = pd.read_csv(metadataHeaders, sep=',').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(enroncsv, names=columns, sep='|', low_memory=False)\n",
    "\n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "removableColumns = pd.read_csv('data/removableColumns.csv', sep=',').columns.tolist()\n",
    "\n",
    "df.drop(removableColumns, axis=1)\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "listOfEmailsForBagOfWords = df.loc[df['Directory'].str.contains('inbox')]\n",
    "\n",
    "print('-- DONE --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = df[pd.notnull(df['Subject'])]\n",
    "nonSpamSubjects = wordsPerEmail['Subject']\n",
    "wordsPerEmail = nonSpamSubjects.str.split(' ')\n",
    "len(wordsPerEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "printable = set(string.printable)\n",
    "\n",
    "def isEnglish(s):\n",
    "    for x in s:\n",
    "        if x not in printable:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def addToBagOfWords(dictionary, arr):\n",
    "    for word in arr:\n",
    "        word = word.lower()\n",
    "        \n",
    "        if '=' in word:\n",
    "            continue\n",
    "        if '/' in word:\n",
    "            continue\n",
    "        if '\\\\' in word:\n",
    "            continue\n",
    "        if '_' in word:\n",
    "            continue\n",
    "        if '-' in word:\n",
    "            continue\n",
    "        if ':' in word:\n",
    "            continue\n",
    "        if '@' in word:\n",
    "            continue\n",
    "        if '#' in word:\n",
    "            continue\n",
    "        if '$' in word:\n",
    "            word = '$'\n",
    "\n",
    "        word = word.replace('.', '')\n",
    "        word = word.replace(')', '')\n",
    "        word = word.replace('(', '')\n",
    "        word = word.replace('&', '')\n",
    "        word = word.replace('\\'', '')\n",
    "        word = word.replace('\\\"', '')\n",
    "        word = word.replace(',', '')\n",
    "        word = word.replace('[', '')\n",
    "        word = word.replace(']', '')\n",
    "        word = word.replace('{', '')\n",
    "        word = word.replace('}', '')\n",
    "        word = word.replace(';', '')\n",
    "\n",
    "        if word == '':\n",
    "            continue\n",
    "\n",
    "        if word in dictionary:\n",
    "            dictionary[word] = dictionary[word] + 1\n",
    "        else:\n",
    "            dictionary[word] = 1\n",
    "            \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToDictionary(dictionary, arr):\n",
    "    for index, subject in arr.iteritems():\n",
    "        dictionary = addToBagOfWords(dictionary, subject)\n",
    "                \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39519"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spamSubjects = pd.read_csv(spam, names=['Subject'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45090"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsPerEmail = spamSubjects['Subject'].str.split(' ')\n",
    "\n",
    "dictionary = addToDictionary(dictionary, wordsPerEmail)\n",
    "        \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45090"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = []\n",
    "for key in dictionary:\n",
    "    dictionaryList.append([key, dictionary[key]])\n",
    "    \n",
    "dictionaryList = pd.DataFrame(dictionaryList, columns=[\"Word\", \"Occurances\"])\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use words that occurred more than 30 times in our bag of words as other words would almost never match up anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5751"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaryList = dictionaryList.loc[dictionaryList['Occurances'] > 30].reset_index(drop=True)\n",
    "len(dictionaryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addBagToInputOutput(inputItems, outputItems, arr):\n",
    "    for index, subject in inputItems.iteritems():\n",
    "        posBagOfWords = {}\n",
    "        posBagOfWords = addToBagOfWords(posBagOfWords, subject)\n",
    "\n",
    "        listOfIn = []\n",
    "        for key in posBagOfWords:\n",
    "            listOfIn.append(key)\n",
    "\n",
    "        inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "\n",
    "        arr.append([np.array(inputBag), np.array(outputItems)])\n",
    "        \n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "\n",
    "NON_SPAM_SAMPLES = 5000\n",
    "SPAM_SAMPLES = 5000\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "training = addBagToInputOutput(trainingPosSplit, [0], training)\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "    \n",
    "training = addBagToInputOutput(trainingNegSplit, [1], training)\n",
    "\n",
    "training = np.array(training)\n",
    "np.random.shuffle(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up a neuarl network with neurons on each layer \n",
    "\n",
    "    input - 5558 + bias\n",
    "    hidden layer 1 - 200 + bias\n",
    "    hidden layer 2 - 20 + bias\n",
    "    output - 1\n",
    "    \n",
    "The learing rate is set to 0.001\n",
    "The netword is bound to (-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.numberGenerator.bounds import Bounds\n",
    "from mlpy.neuralNetwork.feedForwardNeuralNetwork import NeuralNetwork\n",
    "from mlpy.neuralNetwork.structure.layer import Layer\n",
    "\n",
    "l_rate = 0.001\n",
    "bounds = Bounds(-2, 2)\n",
    "\n",
    "inputLayer = Layer(bounds, size = len(training[0][0]), prev = None, l_rate = l_rate, bias = True, label = \"Input layer\")\n",
    "hiddenLayer = Layer(bounds, size = 300, prev = inputLayer, l_rate = l_rate, bias = True, label = \"Hidden layer\")\n",
    "hiddenLayer2 = Layer(bounds, size = 30, prev = hiddenLayer, l_rate = l_rate, bias = True, label = \"Hidden layer 2\")\n",
    "outputLayer = Layer(bounds, size = len(training[0][1]), prev = hiddenLayer2, l_rate = l_rate, bias = False, label = \"Output layer\")\n",
    "\n",
    "fnn = NeuralNetwork()\n",
    "fnn.appendLayer(inputLayer)\n",
    "fnn.appendLayer(hiddenLayer)\n",
    "fnn.appendLayer(hiddenLayer2)\n",
    "fnn.appendLayer(outputLayer)\n",
    "\n",
    "group_training = np.array([input[0] for input in training])\n",
    "group_target = np.array([output[1] for output in training])\n",
    "\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run training over 4000 iterations and output the mean error every 200 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting..\n",
      "0.0%\t -0.4450697749411331\n",
      "1.0%\t 0.29226000483151027\n",
      "1.0%\t 0.2405027732987663\n",
      "2.0%\t 0.1954854436858978\n",
      "2.0%\t 0.17313789342753572\n",
      "3.0%\t 0.15726717406373292\n",
      "4.0%\t 0.14344714953510274\n",
      "4.0%\t 0.13106350756075108\n",
      "5.0%\t 0.11778761098294012\n",
      "6.0%\t 0.10632641354864045\n",
      "6.0%\t 0.09610899886848875\n",
      "7.0%\t 0.08611479140441503\n",
      "8.0%\t 0.07728473232425703\n",
      "8.0%\t 0.07007627043212522\n",
      "9.0%\t 0.06369097624858991\n",
      "9.0%\t 0.057724256279247536\n",
      "10.0%\t 0.050774727186782845\n",
      "11.0%\t 0.04185855124310962\n",
      "11.0%\t 0.034109152036517446\n",
      "12.0%\t 0.03096131048977368\n",
      "12.0%\t 0.029904630350282804\n",
      "13.0%\t 0.027815852113728372\n",
      "14.0%\t 0.024176040745667496\n",
      "14.0%\t 0.01822952608050097\n",
      "15.0%\t 0.017192570541871358\n",
      "16.0%\t 0.025202318711006467\n",
      "16.0%\t 0.014860932034512112\n",
      "17.0%\t 0.0030147048322294117\n",
      "18.0%\t 0.0002670460843255359\n",
      "18.0%\t -0.0004087518182566617\n",
      "19.0%\t -0.0005260359385565932\n",
      "19.0%\t -0.0005788383987213834\n",
      "20.0%\t -0.0007391021476301161\n",
      "21.0%\t -0.0009247383694778923\n",
      "21.0%\t -0.0010733079936943724\n",
      "22.0%\t -0.0011747345258443995\n",
      "22.0%\t -0.0012353708200198395\n",
      "23.0%\t -0.001292397230535933\n",
      "24.0%\t -0.0013527583435232946\n",
      "24.0%\t -0.0014332898678003202\n",
      "25.0%\t -0.0015345007268843984\n",
      "26.0%\t -0.0015960891586872007\n",
      "26.0%\t -0.0016314511740118615\n",
      "27.0%\t -0.001666230584618905\n",
      "28.0%\t -0.001691426058657099\n",
      "28.0%\t -0.0017101784865023986\n",
      "29.0%\t -0.0017348570980229546\n",
      "29.0%\t -0.0017620665702887176\n",
      "30.0%\t -0.0017640696988594313\n",
      "31.0%\t -0.0017360225676061323\n",
      "31.0%\t -0.0016979561521357634\n",
      "32.0%\t -0.001661624425038172\n",
      "32.0%\t -0.0016768198450229008\n",
      "33.0%\t -0.0016962597477575947\n",
      "34.0%\t -0.0016406994026367532\n",
      "34.0%\t -0.0015290929146748685\n",
      "35.0%\t -0.0014454021466321965\n",
      "36.0%\t -0.0013811027956635187\n",
      "36.0%\t -0.0012946673661590317\n",
      "37.0%\t -0.0011961025685833823\n",
      "38.0%\t -0.0011710989683103436\n",
      "38.0%\t -0.001187485849443245\n",
      "39.0%\t -0.0011984069274745149\n",
      "39.0%\t -0.001219405731228218\n",
      "40.0%\t -0.0012366266340301222\n",
      "41.0%\t -0.0012320999491197\n",
      "41.0%\t -0.0011884868139675334\n",
      "42.0%\t -0.0010718246456641926\n",
      "42.0%\t -0.0009483554196997304\n",
      "43.0%\t -0.0009246181099756917\n",
      "44.0%\t -0.0009058080310656037\n",
      "44.0%\t -0.0009290136206612037\n",
      "45.0%\t -0.0010221599205462461\n",
      "46.0%\t -0.0011280781128777345\n",
      "46.0%\t -0.0011349886197280265\n",
      "47.0%\t -0.001098352955785766\n",
      "48.0%\t -0.001085653205088261\n",
      "48.0%\t -0.0010389347536106396\n",
      "49.0%\t -0.0009008157586107018\n",
      "49.0%\t -0.0009390385940830971\n",
      "50.0%\t -0.0009838947898346188\n",
      "51.0%\t -0.0009747206619595914\n",
      "51.0%\t -0.0008876958567632878\n",
      "52.0%\t -0.0008458637829957175\n",
      "52.0%\t -0.0008712160657467845\n",
      "53.0%\t -0.0008886665766338988\n",
      "54.0%\t -0.0008737206158403722\n",
      "54.0%\t -0.0008367249318882216\n",
      "55.0%\t -0.0007819957378643732\n",
      "56.0%\t -0.000766315381863207\n",
      "56.0%\t -0.000812699012115719\n",
      "57.0%\t -0.000870215261681243\n",
      "57.0%\t -0.0009250729554925762\n",
      "58.0%\t -0.0009678712818039672\n",
      "59.0%\t -0.0009976823437755768\n",
      "59.0%\t -0.0010164341865874643\n",
      "60.0%\t -0.0010235798412977224\n",
      "61.0%\t -0.0010211174886321306\n",
      "61.0%\t -0.0010135468512345723\n",
      "62.0%\t -0.0010018555771130577\n",
      "62.0%\t -0.0009854585204668708\n",
      "63.0%\t -0.0009646563172292513\n",
      "64.0%\t -0.0009404379724894814\n",
      "64.0%\t -0.0009131034387864798\n",
      "65.0%\t -0.0008809329809902021\n",
      "66.0%\t -0.0008401688400754139\n",
      "66.0%\t -0.000785789518690845\n",
      "67.0%\t -0.0007081792540867897\n",
      "68.0%\t -0.0005886675029956085\n",
      "68.0%\t -0.00047189440097105084\n",
      "69.0%\t -0.0004621130107606385\n",
      "69.0%\t -0.0004880532556729975\n",
      "70.0%\t -0.0005126271664208963\n",
      "71.0%\t -0.0005228196445223217\n",
      "71.0%\t -0.0005113712941579349\n",
      "72.0%\t -0.00047713445970724513\n",
      "72.0%\t -0.00040231926382416444\n",
      "73.0%\t -0.0003394961781918713\n",
      "74.0%\t -0.00030396516953855155\n",
      "74.0%\t -0.00025334251001916036\n",
      "75.0%\t -0.0002436110748641619\n",
      "76.0%\t -0.0002576656100286357\n",
      "76.0%\t -0.0002664975348939864\n",
      "77.0%\t -0.00026857664816260163\n",
      "78.0%\t -0.00026468905255704945\n",
      "78.0%\t -0.00025430848036079966\n",
      "79.0%\t -0.00023525020680821863\n",
      "79.0%\t -0.00020452618417990482\n",
      "80.0%\t -0.0001696335583914067\n",
      "81.0%\t -0.0001589121182715969\n",
      "81.0%\t -0.00018101902187921847\n",
      "82.0%\t -0.00024860354580758524\n",
      "82.0%\t -0.0004638135010448829\n",
      "83.0%\t -0.0007358982168782308\n",
      "84.0%\t -0.0004936291199689529\n",
      "84.0%\t -0.00030763780116214507\n",
      "85.0%\t -0.00014813639203462082\n",
      "86.0%\t -1.7722364909418875e-05\n",
      "86.0%\t 4.725589343021141e-06\n",
      "87.0%\t 1.0833625251366818e-05\n",
      "88.0%\t 6.179377607367762e-05\n",
      "88.0%\t 0.00013280441866789916\n",
      "89.0%\t 6.029213396403854e-05\n",
      "89.0%\t 1.196935270124193e-05\n",
      "90.0%\t -3.998725362331239e-05\n",
      "91.0%\t -0.0001284338383184039\n",
      "91.0%\t -0.0003301651692240791\n",
      "92.0%\t -0.00032969165989362245\n",
      "92.0%\t -0.0003162612493479442\n",
      "93.0%\t -0.0003509973415304136\n",
      "94.0%\t -0.00044845430284776064\n",
      "94.0%\t -0.000415729105355663\n",
      "95.0%\t -0.00034205609576017597\n",
      "96.0%\t -0.0002838248945100592\n",
      "96.0%\t -0.00019098485953464035\n",
      "97.0%\t -6.140122292450663e-05\n",
      "98.0%\t -5.108302278940258e-05\n",
      "98.0%\t 0.00012299251767297398\n",
      "99.0%\t 0.00012877505587902203\n",
      "99.0%\t 8.110443255111246e-05\n",
      "-- DONE --\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 8000\n",
    "\n",
    "print(\"Starting..\")\n",
    "for i in range(ITERATIONS):\n",
    "    mod = i % len(training)\n",
    "    in_out = training[mod]\n",
    "    result = fnn.fire(group_training)\n",
    "    error = fnn.backPropagation(group_target)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(str(np.round(i/ITERATIONS*100)) + '%\\t', error.mean())\n",
    "    \n",
    "print(\"-- DONE --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = []\n",
    "\n",
    "TEST_NON_SPAM_SAMPLES = 500\n",
    "TEST_SPAM_SAMPLES = 500\n",
    "\n",
    "trainingPos = df[pd.notnull(df['Subject'])]\n",
    "trainingPos = trainingPos.sample(TEST_NON_SPAM_SAMPLES)\n",
    "trainingPos = trainingPos['Subject']\n",
    "\n",
    "trainingPosSplit = trainingPos.str.split(' ')\n",
    "\n",
    "testing = addBagToInputOutput(trainingPosSplit, [0], testing)\n",
    "    \n",
    "trainingNeg = spamSubjects.sample(TEST_SPAM_SAMPLES)\n",
    "trainingNeg = trainingNeg['Subject']\n",
    "\n",
    "trainingNegSplit = trainingNeg.str.split(' ')\n",
    "\n",
    "testing = addBagToInputOutput(trainingNegSplit, [1], testing)\n",
    "\n",
    "testing = np.array(testing)\n",
    "np.random.shuffle(testing)\n",
    "\n",
    "len(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model we will take the test data and use it as an measure of performace. The following will be output:\n",
    "\n",
    "1. The Classification Accuracy\n",
    "2. The Non-spam Classsification accuracy\n",
    "3. The Spam Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.858\n",
      "Non spam classification accuracy:  0.852\n",
      "Spam classification accuracy:  0.864\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "spamCorrect = 0\n",
    "nonSpamCorrect = 0\n",
    "for i in range(len(testing)):\n",
    "    in_out = testing[i]\n",
    "    result = fnn.fire(np.array([in_out[0]]))\n",
    "    \n",
    "    target = in_out[1][0]\n",
    "    result = np.round(result[0][0])\n",
    "\n",
    "    if result == target:\n",
    "        correct += 1\n",
    "        if target == 1:\n",
    "            spamCorrect += 1\n",
    "        else:\n",
    "            nonSpamCorrect += 1\n",
    "        \n",
    "        \n",
    "print(\"Classification accuracy: \", correct / len(testing))\n",
    "print(\"Non spam classification accuracy: \", nonSpamCorrect / TEST_NON_SPAM_SAMPLES)\n",
    "print(\"Spam classification accuracy: \", spamCorrect / TEST_SPAM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets apply the classifier to a subset of the data to see what it classifies as spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206342</th>\n",
       "      <td>Win $10,000! Free Photography Contest- Enter Now!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261656</th>\n",
       "      <td>Register to win a free cruise to Island</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348536</th>\n",
       "      <td>DB credit swap (Loews as the Reference Credit)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126000</th>\n",
       "      <td>FW: You will like this</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230853</th>\n",
       "      <td>Monica - Vacation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Subject  Classification\n",
       "206342  Win $10,000! Free Photography Contest- Enter Now!             1.0\n",
       "261656            Register to win a free cruise to Island             1.0\n",
       "348536     DB credit swap (Loews as the Reference Credit)             1.0\n",
       "126000                             FW: You will like this             1.0\n",
       "230853                                  Monica - Vacation             1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClassify = df.drop(['Filename', 'Person', 'Directory', 'Message-ID', 'Content-Transfer-Encoding', 'Content-Type', 'Date', 'X-FileName', 'From', 'X-To', 'X-bcc', 'Cc', 'X-cc', 'To', 'X-Folder', 'X-Origin', 'Time', 'Bcc', 'X-From', 'Attendees', 'Re', 'Mime-Version'], axis=1)\n",
    "\n",
    "dfClassify = dfClassify[pd.notnull(df['Subject'])]\n",
    "dfClassify = dfClassify.sample(10000)\n",
    "\n",
    "def classify(arr):\n",
    "    classifySplit = arr.split(' ')\n",
    "    \n",
    "    posBagOfWords = {}\n",
    "    posBagOfWords = addToBagOfWords(posBagOfWords, classifySplit)\n",
    "\n",
    "    listOfIn = []\n",
    "    for key in posBagOfWords:\n",
    "        listOfIn.append(key)\n",
    "\n",
    "    inputBag = dictionaryList['Word'].isin(listOfIn).values.tolist()\n",
    "    \n",
    "    result = fnn.fire(np.array([np.array(inputBag)]))[0][0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "dfClassify['Classification'] = dfClassify['Subject'].apply(classify)\n",
    "    \n",
    "dfClassify.sort_values(['Classification'], ascending=[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
